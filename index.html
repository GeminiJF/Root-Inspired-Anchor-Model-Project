<!DOCTYPE html>
<html lang = "en">
<head>
  <title> Root Inspired Anchor Model Project </title>
  <link rel="stylesheet" href="styles/style.css">
  <meta charset="UTF-8">
</head>
<h1>
  Root Inspired Anchor Model Project
</h1>
<h6> A project by Muhao Feng, Zhen Jiang, Yihua Xu;
</h6>
<h6>supervised by Seth Mallett, Mahdi Roozbahani.</h6>

<body>

<h2>
  Introduction
</h2>

<h3> Motivation:
</h3>
<img src= "pictures/practical use.jpg" width = "525" height = "360" alt="Root Inspire Model Practical example" align = "center">
<p> Just as the picture suggests, A wall separating two platforms has different elevations. The wall shown in the picture has a tendency to incline to the right because the mass on the left side of the wall is much greater. Therefore, we attach this root-inspired anchor model into the wall, which provides the resistance against the force on the left side.
</p>
<br/>
<img src= "pictures/high-voltage_transmission_tower_933-3121_big.jpg" width = "525" height = "360" alt="Root Inspire Model Practical example" align = "center">
<p>
  In the real world setting, this model is of great significance! For example, we can utilize this model in transmission towers. Because of the wind blowing and the weight of the wire, sometimes, the foundation is not solid enough and may get uplifted. Then, the anchored model came into practice. People can implement them down the ground, and make the structure as solid as possible. Other than that, we can also utilize the same model in retaining wall, solidifying dams, and reinforcing the slope.
</p>
<br/>
<p> During experiments, Dr. Mallet took steps of embedding the model into the soil, and then utilized machines to vertically pull up the anchor. After repetitive experiments using different models and particulates, 181 data sets are collected.
</p>
<img src= "pictures/root.png" width = "360" height = "525" alt="Root Inspire Model exhibition">

<h2><b> Problems that we are striving to solve
  </b>
</h2>
  <ul style="list-style-type:disc;">
  <li> How different features contribute to the pullout capacity of our root-inspired Model? </li>
  <li> How accurate datasets can predict the pullout force? </li>
  <li> How different algorithms lead to an accuracy difference? Why? </li>
  <li> How unique features vs interdependent features lead to different predictive models? </li>
  <li> What can be improved for our predictive model?  </li>
</ul>

<h2>
  Brief Definition of Terms
</h2>

<h3>
  Input Terms:
</h3>
<p> Number of branches ( n[count] )
</p>
<p>Internal branching angle ( α [°] )
</p>
<p>Length of the branch ( L [mm] )
</p>
<P>Total height of the model ( H [mm] )
</p>
<p>Horizontal width ( b[mm] )
</p>
<p>Length of the stem ( Ls [mm] )
</p>
<P>Diameter of the model ( d [mm] )
</p>
<p>Radians between each branch, evenly distributed ( 2π/n [rad] )
</p>
<p>Property of soil (Unit Weight Force) ( γ [N/mm3] )
</p>
<P> Displacement made by the pullout force ( δ(Pmax) [mm] )
</p>
<p> The derivative of the Pmax over displacement (max(ktan) [N/mm])
</p>
<p> Weight of the soil immediately above model (γAH' [N])
</p>
<P>Volume of the model ( Vroot [mm3] )
</p>
<p>Initial start pull force ( P0 [N] )
</p>
<p>Soil relative density ( DR [ ] )
</p>
<p>Material
</p>
<P> Mean diameter of the sand ( d50 [mm] )
</p>
<p>Strength of the soil, friction angle ( φ [°] )
</p>
<p>Weight of soil’s length to the whole length ( f )
</p>
<p>  Total number of Features: 19
</p>

<h3>
  Output Terms:
</h3>
<p>
  Maximum pullout force ( Pmax [N] )
</p>

<h2>
  Project Objective
</h2>
<p>
  The objective of this project is to develop a machine-learning-based method to predict and calculate the pullout force. To make this project more feasible to carry out, we will only use the features that are unique (not dependent on other properties).
</p>
<p> Our group implements different algorithms to yield the best prediction models.
</p>



<h2> Methodology
</h2>
<img src= "pictures/Procedure.png" width = "800" height = "350" alt="Problem Solving Procedure" align = "center">
<h3> <b> Before Everything: </b>
</h3>
<ul style="list-style-type:circle;">
  <li> When we received our data set, we found that we have 19 features. Some of the features are interrelated with each other, for example, two features’ named γAH' [N] and Nγ [ ], their multiplication equals to the maximum pullout force, which can not be utilized as the features.
  </li>
</ul>
<br>
<h3> <b> Data Preprocessing: </b>
</h3>
<ul>
  <li> There are several data points with values “inf” or “NaN”, by removing these data points, our final data points become 177.
  </li>
  <li> Since the scale of each feature is quite different, we need to utilize the normalization. By calculating all features’ mean and sigma(StandardScaler()), our data is normalized and ready to go.
  </li>
</ul>
<br>
<h3> <b> Dimension Reduction: </b>
</h3>
<ul>
  <li> 1. After reducing interdependent features, what we are left with are 17 unique features. These 17 unique features are still too many for us because when we apply our algorithms, we didn’t get satisfactory results. (Some of the features are actually not of great importance.) Consequently, we decided to reduce our dimensions.
  </li>
</ul>
<h5> <b> Two Strategies are utilized </b>
</h5>
<ul>
  <li> a. By capturing variance, Principal Component Analysis is implemented to reduce the dimensions. After PCA, our dimensions are reduced to 7.
  </li>
  <li> b. One other way is through choosing a subset of features that maximizes information gain from all features. By doing so, we managed to figure out the best feature. And our dimensions are reduced to 6.
  </li>
</ul>
<img src= "pictures/T_Accuracy_for_Unique_Best_Features.png" width = "800" height = "350" alt="Best Feature seletion line dot" align = "center">
<br>
<h3> Data Split
</h3>
<p> The ratio of test data to training data was kept constant at 3 to 1 for each model.
</p>
<br>
<h3> Random Forest:
</h3>
<ul>
  <li> To avoid potential overfitting problems generated by a decision tree, we utilized Ensemble learning algorithm -- Random Forest. Several samples of data are created by random sampling from the dataset with replacement. The results (the graph below) suggest that our predictive value of the pullout capacity has a value of 85.82% of the predictive accuracy generated by the data feature dataset. Opposingly, the accuracy brought by the PCA dataset gives us 84.06%.
  </li>
</ul>



<p>
  <img src= "pictures/T_before_CV_hyperparameter.png" style = "width:50%;height:50%" alt="Tree before Hyperparameter">
  <img src= "pictures/T_PCA_plot.png" style = "width:50%;height:50%" alt="Tree after hyperparameter">
</p>

<ul>
  <li> Then, we started to implement hyperparameter optimization and our predictive model got a better result. Originally, our “n-estimator”(decision tree quantity) is 1000, and “random-state” is a random number. However, after tuning, “n-estimator” is set to 281, and the parameter named “random-state” is tuned to be 187. The accuracy boosted to 86.17%.
  </li>
</ul>
<img src= "pictures/Accuracy_BA_Hyper.png" width = "800" height = "350" alt="Random Forest Compare Before and After Hyperparameter">
<p>In order to achieve a more accurate result, K fold cross-validation was also implemented for the data set. By combatting the overfitting issue, 10 fold validation is used in congruence with Random Forest ensemble learning. This means we utilize the same random forest algorithm, however, each 10% of data acted as the test data for one iteration. On average, for 2-10 fold validation, the average k-fold value is 0.89834. This means that our predictive model is pretty reliable and successful.
</p>





<h2> <b> Future improvement: </b>
</h2>

<p> There are several improvements that we can probably do in order to make our predictive model even better. Firstly, the measurement of data could have some errors because of the operation of data measurement. We get the pullout force by analyzing the amount of soil being pullout (which could not be exactly accurate). We also have some bad data in our data, we already removed them and reduced the number of datasets for better results. For example, the feature named n-count, one of the possible input is infinity (which can not be converted to quantified data easily), we have to use a certain method (np.dummies) to treat this as new features. This may make our predictive model less accurate.
</p>
<br/>
<p> Furthermore, under the circumstance that we only have 177 data inputs, if we could have more data points, we could definitely utilize more of them to become our train/ test/ validation parts. It could probably prevent overfitting more effectively, therefore enhance the predictive model quality.
</p>
<br/>
<p> Also, as we are getting to learn more machine learning and data mining related knowledge, we would like to apply feature engineering into our predictive models. By doing this, we can adapt to a wider variety of conditions.
</p>
<br/>
<p> Finally, while applying these predictive models into practice, we should research into more soil types. Currently, we only researched into three types of soil, and we are definitely encountering more in the real setting.
</p>

<img src= "pictures/tree.png" width = "800" height = "350" alt="Decision Tree before Hyperparameter" align = "center">
<img src= "pictures/tree_after_hype.png" width = "800" height = "350" alt="Decision tree after hyperparamter" align = "center">
<img src= "pictures/T_RBF_plot.png" width = "800" height = "350" alt="Kernel RBF plot" align = "center">
<img src= "pictures/Logistic_Regression_plot.png" width = "800" height = "350" alt="Logistic Regression" align = "center">












<h4>
  <b> Reference: </b>
</h4>
<ul style="list-style-type:disc;" class = "methods">
  <li> 1. Mallett, Seth, “Additive Manufacturing and Computed Tomography of Bio-Inspired Anchorage Systems.” Géotechnique Letters, Accessed 07 June 2019 www.icevirtuallibrary.com/doi/full/10.1680/jgele.18.00090. </li>
  <li> 2. Moayedi, Hossein, and Abbas Rezaei. "An artificial neural network approach for under-reamed piles subjected to uplift forces in dry sand." SpringerLink. 04 Apr. 2017. Springer London. Accessed 08 June 2019 https://link.springer.com/article/10.1007/s00521-017-2990-z. </li>
  <li> 3. V.F.Rodriguez-Galiano, B.Ghimire, J.Rogan, M.Chica-Olmo, J.P.Rigol-Sanchez, "An assessment of the effectiveness of a random forest classifier for land-cover classification." ISPRS Journal of Photogrammetry and Remote Sensing. 01 Dec. 2011. Accessed 11 June 2019  </li>
  <li> 4. "Time series prediction using artificial wavelet neural network and multi-resolution analysis: Application to wind speed data." Renewable Energy. 15 Feb. 2016. Pergamon. 16 July 2019 https://www.sciencedirect.com/science/article/pii/S0960148116301045. </li>
</ul>

</body>
</html>
